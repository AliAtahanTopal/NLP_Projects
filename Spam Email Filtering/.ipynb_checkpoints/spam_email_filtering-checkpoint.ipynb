{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import heapq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data and generating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_legitimate_train = \"C:\\\\Users\\\\DarthZiox\\\\Desktop\\\\Homeworks\\\\COMP4602\\\\Assignment 3\\\\dataset\\\\training\\\\legitimate\"\n",
    "path_spam_train = \"C:\\\\Users\\\\DarthZiox\\\\Desktop\\\\Homeworks\\\\COMP4602\\\\Assignment 3\\\\dataset\\\\training\\\\spam\"\n",
    "path_legitimate_test = \"C:\\\\Users\\\\DarthZiox\\\\Desktop\\\\Homeworks\\\\COMP4602\\\\Assignment 3\\\\dataset\\\\test\\\\legitimate\"\n",
    "path_spam_test = \"C:\\\\Users\\\\DarthZiox\\\\Desktop\\\\Homeworks\\\\COMP4602\\\\Assignment 3\\\\dataset\\\\test\\\\spam\"\n",
    "all_files_test_legitimate = os.listdir(path_legitimate_test)\n",
    "all_files_test_spam = os.listdir(path_spam_test)\n",
    "all_files_train_legitimate = os.listdir(path_legitimate_train)\n",
    "all_files_train_spam = os.listdir(path_spam_train)\n",
    "test_legitimate = []\n",
    "test_spam_mails = []\n",
    "train_legitimate = []\n",
    "train_spam_mails = []\n",
    "\n",
    "for fle in all_files_train_legitimate:\n",
    "    with open(os.path.join(str(path_legitimate_train), fle)) as f:\n",
    "        text = f.read()\n",
    "        train_legitimate.append(text)\n",
    "    \n",
    "for fle in all_files_train_spam:\n",
    "    with open(os.path.join(str(path_spam_train), fle)) as f:\n",
    "        text = f.read()\n",
    "        train_spam_mails.append(text)\n",
    "        \n",
    "for fle in all_files_test_legitimate:\n",
    "    with open(os.path.join(str(path_legitimate_test), fle)) as f:\n",
    "        text = f.read()\n",
    "        test_legitimate.append(text)\n",
    "    \n",
    "for fle in all_files_test_spam:\n",
    "    with open(os.path.join(str(path_spam_test), fle)) as f:\n",
    "        text = f.read()\n",
    "        test_spam_mails.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_legit = pd.DataFrame(columns = ['Type', 'E-Mail'])\n",
    "train_spam = pd.DataFrame(columns = ['Type', 'E-Mail'])\n",
    "for i in range(len(train_legitimate)):    \n",
    "    train_legit = train_legit.append({'Type': 'legitimate',\n",
    "                                      'E-Mail': train_legitimate[i]}, ignore_index = True)\n",
    "    train_spam = train_spam.append({'Type': 'spam', \n",
    "                                    'E-Mail': train_spam_mails[i]}, ignore_index = True)\n",
    "train_legit = train_legit.sort_values('Type').reset_index(drop = True)\n",
    "train_spam = train_spam.sort_values('Type').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_legit = pd.DataFrame(columns = ['Type', 'E-Mail'])\n",
    "test_spam = pd.DataFrame(columns = ['Type', 'E-Mail'])\n",
    "for i in range(len(test_legitimate)):    \n",
    "    test_legit = test_legit.append({'Type': 'legitimate',\n",
    "                                    'E-Mail': test_legitimate[i]}, ignore_index = True)\n",
    "    test_spam = test_spam.append({'Type': 'spam', \n",
    "                                  'E-Mail': test_spam_mails[i]}, ignore_index = True)\n",
    "test_legit = test_legit.sort_values('Type').reset_index(drop = True)\n",
    "test_spam = test_spam.sort_values('Type').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>E-Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np\\n\\n&gt; deat : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: george aditjondro\\n\\ndr george aditjo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: ua appeal : arief budiman\\n\\nurgent a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: \" design \" dialect\\n\\nfollow appear r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: language evolution context\\n\\nhello l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: conference aisb ' 93 call paper\\n\\n= ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: close linguistic soas call help ! ! !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: soas cease publication cancel linguis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: translator\\n\\norder form translator s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: special issue\\n\\nname , journal ameri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type                                             E-Mail\n",
       "0    legitimate  Subject: re : 2 . 882 s - > np np\\n\\n> deat : ...\n",
       "1    legitimate  Subject: george aditjondro\\n\\ndr george aditjo...\n",
       "2    legitimate  Subject: ua appeal : arief budiman\\n\\nurgent a...\n",
       "3    legitimate  Subject: \" design \" dialect\\n\\nfollow appear r...\n",
       "4    legitimate  Subject: language evolution context\\n\\nhello l...\n",
       "..          ...                                                ...\n",
       "235  legitimate  Subject: conference aisb ' 93 call paper\\n\\n= ...\n",
       "236  legitimate  Subject: close linguistic soas call help ! ! !...\n",
       "237  legitimate  Subject: soas cease publication cancel linguis...\n",
       "238  legitimate  Subject: translator\\n\\norder form translator s...\n",
       "239  legitimate  Subject: special issue\\n\\nname , journal ameri...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>E-Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: position announcement\\n\\ndepartment n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: \\n\\nsyntax wesley hudson . pragmatic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: comparative method\\n\\nnote after rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: open letter * language *\\n\\nown behal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: vacation\\n\\ndear subscriber : 's holi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: int ' l directory scholar\\n\\ndear lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: point contact thailand\\n\\ndear netter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: text structure modern english\\n\\ncoll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: iawe : conference alert\\n\\n\" third in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>Subject: query : preserve field recording\\n\\nq...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type                                             E-Mail\n",
       "0    legitimate  Subject: position announcement\\n\\ndepartment n...\n",
       "1    legitimate  Subject: \\n\\nsyntax wesley hudson . pragmatic ...\n",
       "2    legitimate  Subject: comparative method\\n\\nnote after rece...\n",
       "3    legitimate  Subject: open letter * language *\\n\\nown behal...\n",
       "4    legitimate  Subject: vacation\\n\\ndear subscriber : 's holi...\n",
       "..          ...                                                ...\n",
       "235  legitimate  Subject: int ' l directory scholar\\n\\ndear lin...\n",
       "236  legitimate  Subject: point contact thailand\\n\\ndear netter...\n",
       "237  legitimate  Subject: text structure modern english\\n\\ncoll...\n",
       "238  legitimate  Subject: iawe : conference alert\\n\\n\" third in...\n",
       "239  legitimate  Subject: query : preserve field recording\\n\\nq...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_legit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataframe (removing all tokens and splitting messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spam['E-Mail'] = train_spam['E-Mail'].str.replace('\\W+', ' ', regex = True).str.replace('\\s+', ' ', regex=True).str.replace('\\d+', ' ', regex = True).str.replace('_', ' ').str.strip()\n",
    "train_spam['E-Mail'] = train_spam['E-Mail'].str.lower()\n",
    "train_spam['E-Mail'] = train_spam['E-Mail'].str.split()\n",
    "\n",
    "train_legit['E-Mail'] = train_legit['E-Mail'].str.replace('\\W+', ' ', regex = True).str.replace('\\s+', ' ', regex=True).str.replace('\\d+', ' ', regex = True).str.replace('_', ' ').str.strip()\n",
    "train_legit['E-Mail'] = train_legit['E-Mail'].str.lower()\n",
    "train_legit['E-Mail'] = train_legit['E-Mail'].str.split()\n",
    "\n",
    "test_legit['E-Mail'] = test_legit['E-Mail'].str.replace('\\W+', ' ', regex = True).str.replace('\\s+', ' ', regex=True).str.replace('\\d+', ' ', regex = True).str.replace('_', ' ').str.strip()\n",
    "test_legit['E-Mail'] = test_legit['E-Mail'].str.lower()\n",
    "test_legit['E-Mail'] = test_legit['E-Mail'].str.split()\n",
    "\n",
    "test_spam['E-Mail'] = test_spam['E-Mail'].str.replace('\\W+', ' ', regex = True).str.replace('\\s+', ' ', regex=True).str.replace('\\d+', ' ', regex = True).str.replace('_', ' ').str.strip()\n",
    "test_spam['E-Mail'] = test_spam['E-Mail'].str.lower()\n",
    "test_spam['E-Mail'] = test_spam['E-Mail'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>E-Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, re, s, np, np, deat, sun, dec, est, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, george, aditjondro, dr, george, adit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, ua, appeal, arief, budiman, urgent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, design, dialect, follow, appear, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, language, evolution, context, hello,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, conference, aisb, call, paper, aisb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, close, linguistic, soas, call, help,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, soas, cease, publication, cancel, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, translator, order, form, translator,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, special, issue, name, journal, ameri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type                                             E-Mail\n",
       "0    legitimate  [subject, re, s, np, np, deat, sun, dec, est, ...\n",
       "1    legitimate  [subject, george, aditjondro, dr, george, adit...\n",
       "2    legitimate  [subject, ua, appeal, arief, budiman, urgent, ...\n",
       "3    legitimate  [subject, design, dialect, follow, appear, rec...\n",
       "4    legitimate  [subject, language, evolution, context, hello,...\n",
       "..          ...                                                ...\n",
       "235  legitimate  [subject, conference, aisb, call, paper, aisb,...\n",
       "236  legitimate  [subject, close, linguistic, soas, call, help,...\n",
       "237  legitimate  [subject, soas, cease, publication, cancel, li...\n",
       "238  legitimate  [subject, translator, order, form, translator,...\n",
       "239  legitimate  [subject, special, issue, name, journal, ameri...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>E-Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, position, announcement, department, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, syntax, wesley, hudson, pragmatic, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, comparative, method, note, after, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, open, letter, language, own, behalf,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, vacation, dear, subscriber, s, holid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, int, l, directory, scholar, dear, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, point, contact, thailand, dear, nett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, text, structure, modern, english, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, iawe, conference, alert, third, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>legitimate</td>\n",
       "      <td>[subject, query, preserve, field, recording, q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type                                             E-Mail\n",
       "0    legitimate  [subject, position, announcement, department, ...\n",
       "1    legitimate  [subject, syntax, wesley, hudson, pragmatic, c...\n",
       "2    legitimate  [subject, comparative, method, note, after, re...\n",
       "3    legitimate  [subject, open, letter, language, own, behalf,...\n",
       "4    legitimate  [subject, vacation, dear, subscriber, s, holid...\n",
       "..          ...                                                ...\n",
       "235  legitimate  [subject, int, l, directory, scholar, dear, li...\n",
       "236  legitimate  [subject, point, contact, thailand, dear, nett...\n",
       "237  legitimate  [subject, text, structure, modern, english, co...\n",
       "238  legitimate  [subject, iawe, conference, alert, third, inte...\n",
       "239  legitimate  [subject, query, preserve, field, recording, q...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_legit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the propabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_train = list(set(train_legit['E-Mail'].sum())) + list(set(train_spam['E-Mail'].sum()))\n",
    "len(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(words, contents):\n",
    "    probabilities = []\n",
    "    for word in words:\n",
    "        count = 0\n",
    "        for content in contents:\n",
    "            if word in content:\n",
    "                count += 1\n",
    "        probabilities.append(count / len(contents))\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pd.DataFrame()\n",
    "probs['all_words'] = words_train\n",
    "probs['legit_prob'] = prob(words_train, train_legitimate)\n",
    "probs['spam_prob'] = prob(words_train, train_spam_mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "      <th>legit_prob</th>\n",
       "      <th>spam_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traditional</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>redonda</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>causal</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algebraically</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faculte</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15563</th>\n",
       "      <td>offensive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15564</th>\n",
       "      <td>suite</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15565</th>\n",
       "      <td>architect</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15566</th>\n",
       "      <td>order</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.404167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15567</th>\n",
       "      <td>taste</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15568 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           all_words  legit_prob  spam_prob\n",
       "0        traditional    0.016667   0.058333\n",
       "1            redonda    0.004167   0.000000\n",
       "2             causal    0.008333   0.000000\n",
       "3      algebraically    0.004167   0.000000\n",
       "4            faculte    0.004167   0.000000\n",
       "...              ...         ...        ...\n",
       "15563      offensive    0.000000   0.004167\n",
       "15564          suite    0.008333   0.133333\n",
       "15565      architect    0.004167   0.004167\n",
       "15566          order    0.133333   0.404167\n",
       "15567          taste    0.008333   0.012500\n",
       "\n",
       "[15568 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Document Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_train_counts = Counter(list(train_legit['E-Mail'].sum()))\n",
    "spam_train_counts = Counter(list(train_spam['E-Mail'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 555),\n",
       " ('s', 460),\n",
       " ('subject', 288),\n",
       " ('university', 288),\n",
       " ('de', 254),\n",
       " ('linguistic', 254),\n",
       " ('one', 225),\n",
       " ('work', 177),\n",
       " ('english', 168),\n",
       " ('n', 167),\n",
       " ('e', 157),\n",
       " ('linguistics', 154),\n",
       " ('t', 149),\n",
       " ('linguist', 148),\n",
       " ('word', 143),\n",
       " ('interest', 123),\n",
       " ('department', 117),\n",
       " ('information', 108),\n",
       " ('edu', 106),\n",
       " ('many', 102),\n",
       " ('m', 100),\n",
       " ('science', 97),\n",
       " ('theory', 95),\n",
       " ('our', 94),\n",
       " ('student', 93),\n",
       " ('c', 92),\n",
       " ('study', 92),\n",
       " ('first', 90),\n",
       " ('program', 89),\n",
       " ('d', 89),\n",
       " ('snow', 89),\n",
       " ('form', 85),\n",
       " ('la', 85),\n",
       " ('grammar', 85),\n",
       " ('re', 82),\n",
       " ('case', 80),\n",
       " ('two', 79),\n",
       " ('speak', 78),\n",
       " ('example', 78),\n",
       " ('list', 77),\n",
       " ('issue', 75),\n",
       " ('please', 74),\n",
       " ('y', 74),\n",
       " ('send', 73),\n",
       " ('follow', 72),\n",
       " ('seem', 72),\n",
       " ('b', 72),\n",
       " ('research', 72),\n",
       " ('where', 71),\n",
       " ('question', 70),\n",
       " ('include', 70),\n",
       " ('write', 70),\n",
       " ('school', 70),\n",
       " ('datum', 69),\n",
       " ('paper', 69),\n",
       " ('conference', 68),\n",
       " ('mail', 67),\n",
       " ('term', 67),\n",
       " ('analysis', 67),\n",
       " ('apply', 66),\n",
       " ('book', 66),\n",
       " ('en', 66),\n",
       " ('chomsky', 66),\n",
       " ('most', 65),\n",
       " ('number', 65),\n",
       " ('both', 64),\n",
       " ('thank', 64),\n",
       " ('rule', 64),\n",
       " ('much', 62),\n",
       " ('dr', 62),\n",
       " ('reference', 62),\n",
       " ('teach', 62),\n",
       " ('point', 61),\n",
       " ('course', 61),\n",
       " ('fax', 59),\n",
       " ('even', 59),\n",
       " ('us', 59),\n",
       " ('speaker', 58),\n",
       " ('anyone', 58),\n",
       " ('here', 57),\n",
       " ('problem', 57),\n",
       " ('different', 57),\n",
       " ('address', 56),\n",
       " ('little', 56),\n",
       " ('etc', 56),\n",
       " ('text', 56),\n",
       " ('experience', 56),\n",
       " ('ask', 55),\n",
       " ('between', 55),\n",
       " ('child', 55),\n",
       " ('syntax', 55),\n",
       " ('u', 55),\n",
       " ('area', 55),\n",
       " ('harri', 55),\n",
       " ('those', 54),\n",
       " ('query', 53),\n",
       " ('whether', 53),\n",
       " ('general', 53),\n",
       " ('publish', 53),\n",
       " ('available', 53),\n",
       " ('state', 52),\n",
       " ('over', 52),\n",
       " ('since', 50),\n",
       " ('response', 50),\n",
       " ('teacher', 50),\n",
       " ('hear', 50),\n",
       " ('level', 49),\n",
       " ('speech', 49),\n",
       " ('uk', 49),\n",
       " ('rather', 49),\n",
       " ('g', 49),\n",
       " ('accent', 49),\n",
       " ('mean', 48),\n",
       " ('system', 48),\n",
       " ('thing', 48),\n",
       " ('order', 48),\n",
       " ('field', 48),\n",
       " ('r', 47),\n",
       " ('post', 47),\n",
       " ('french', 47),\n",
       " ('ac', 47),\n",
       " ('structure', 47),\n",
       " ('papers', 47),\n",
       " ('l', 46),\n",
       " ('second', 45),\n",
       " ('name', 45),\n",
       " ('receive', 45),\n",
       " ('dialect', 45),\n",
       " ('need', 45),\n",
       " ('translation', 45),\n",
       " ('concern', 44),\n",
       " ('contact', 44),\n",
       " ('note', 44),\n",
       " ('call', 44),\n",
       " ('tell', 44),\n",
       " ('why', 44),\n",
       " ('citation', 44),\n",
       " ('discussion', 43),\n",
       " ('international', 43),\n",
       " ('is', 43),\n",
       " ('learn', 43),\n",
       " ('provide', 43),\n",
       " ('application', 43),\n",
       " ('base', 42),\n",
       " ('must', 42),\n",
       " ('same', 42),\n",
       " ('type', 42),\n",
       " ('eskimo', 42),\n",
       " ('want', 41),\n",
       " ('human', 41),\n",
       " ('part', 41),\n",
       " ('j', 41),\n",
       " ('v', 41),\n",
       " ('literature', 41),\n",
       " ('john', 40),\n",
       " ('mark', 40),\n",
       " ('still', 40),\n",
       " ('modern', 40),\n",
       " ('world', 39),\n",
       " ('academic', 38),\n",
       " ('possible', 38),\n",
       " ('mention', 38),\n",
       " ('member', 38),\n",
       " ('position', 37),\n",
       " ('another', 37),\n",
       " ('each', 37),\n",
       " ('show', 37),\n",
       " ('particular', 37),\n",
       " ('kind', 37),\n",
       " ('a', 37),\n",
       " ('talk', 36),\n",
       " ('chinese', 36),\n",
       " ('discourse', 36),\n",
       " ('spanish', 36),\n",
       " ('less', 36),\n",
       " ('relate', 35),\n",
       " ('view', 35),\n",
       " ('o', 35),\n",
       " ('own', 35),\n",
       " ('three', 35),\n",
       " ('p', 35),\n",
       " ('help', 35),\n",
       " ('theoretical', 35),\n",
       " ('become', 35),\n",
       " ('result', 35),\n",
       " ('however', 34),\n",
       " ('further', 34),\n",
       " ('th', 34),\n",
       " ('class', 34),\n",
       " ('american', 34),\n",
       " ('lo', 34),\n",
       " ('sample', 34),\n",
       " ('acquisition', 34),\n",
       " ('del', 34),\n",
       " ('far', 33),\n",
       " ('phenomenon', 33),\n",
       " ('suggest', 33),\n",
       " ('publication', 33),\n",
       " ('h', 33),\n",
       " ('approach', 33)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_train_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mail', 1033),\n",
       " ('s', 827),\n",
       " ('order', 808),\n",
       " ('address', 722),\n",
       " ('report', 693),\n",
       " ('our', 644),\n",
       " ('email', 539),\n",
       " ('e', 520),\n",
       " ('money', 510),\n",
       " ('send', 508),\n",
       " ('t', 506),\n",
       " ('list', 489),\n",
       " ('program', 479),\n",
       " ('name', 470),\n",
       " ('free', 469),\n",
       " ('receive', 412),\n",
       " ('business', 394),\n",
       " ('one', 394),\n",
       " ('n', 388),\n",
       " ('work', 369),\n",
       " ('subject', 330),\n",
       " ('information', 325),\n",
       " ('internet', 324),\n",
       " ('over', 317),\n",
       " ('http', 314),\n",
       " ('us', 311),\n",
       " ('com', 300),\n",
       " ('check', 295),\n",
       " ('please', 294),\n",
       " ('day', 286),\n",
       " ('call', 259),\n",
       " ('each', 246),\n",
       " ('service', 245),\n",
       " ('want', 245),\n",
       " ('remove', 244),\n",
       " ('product', 232),\n",
       " ('follow', 229),\n",
       " ('need', 227),\n",
       " ('credit', 225),\n",
       " ('site', 224),\n",
       " ('market', 222),\n",
       " ('here', 214),\n",
       " ('start', 213),\n",
       " ('include', 212),\n",
       " ('many', 205),\n",
       " ('million', 203),\n",
       " ('week', 190),\n",
       " ('fax', 189),\n",
       " ('phone', 187),\n",
       " ('even', 187),\n",
       " ('company', 186),\n",
       " ('offer', 185),\n",
       " ('best', 184),\n",
       " ('sell', 182),\n",
       " ('number', 182),\n",
       " ('d', 180),\n",
       " ('home', 179),\n",
       " ('every', 176),\n",
       " ('most', 176),\n",
       " ('cost', 176),\n",
       " ('pay', 174),\n",
       " ('web', 173),\n",
       " ('software', 171),\n",
       " ('card', 170),\n",
       " ('level', 166),\n",
       " ('letter', 166),\n",
       " ('help', 163),\n",
       " ('first', 162),\n",
       " ('those', 157),\n",
       " ('read', 156),\n",
       " ('ll', 154),\n",
       " ('www', 150),\n",
       " ('nbsp', 149),\n",
       " ('today', 148),\n",
       " ('world', 148),\n",
       " ('own', 143),\n",
       " ('advertise', 143),\n",
       " ('bulk', 142),\n",
       " ('cash', 142),\n",
       " ('place', 141),\n",
       " ('opportunity', 140),\n",
       " ('below', 140),\n",
       " ('income', 140),\n",
       " ('win', 140),\n",
       " ('per', 138),\n",
       " ('cd', 138),\n",
       " ('within', 136),\n",
       " ('click', 136),\n",
       " ('much', 135),\n",
       " ('hour', 134),\n",
       " ('state', 132),\n",
       " ('m', 131),\n",
       " ('show', 130),\n",
       " ('computer', 130),\n",
       " ('live', 130),\n",
       " ('easy', 129),\n",
       " ('re', 128),\n",
       " ('file', 128),\n",
       " ('must', 128),\n",
       " ('message', 127),\n",
       " ('save', 124),\n",
       " ('line', 123),\n",
       " ('month', 122),\n",
       " ('buy', 120),\n",
       " ('available', 120),\n",
       " ('interest', 119),\n",
       " ('success', 119),\n",
       " ('net', 116),\n",
       " ('copy', 116),\n",
       " ('through', 114),\n",
       " ('add', 113),\n",
       " ('form', 113),\n",
       " ('before', 113),\n",
       " ('down', 112),\n",
       " ('financial', 112),\n",
       " ('after', 110),\n",
       " ('back', 108),\n",
       " ('dollar', 107),\n",
       " ('ever', 107),\n",
       " ('right', 106),\n",
       " ('earn', 103),\n",
       " ('is', 103),\n",
       " ('try', 103),\n",
       " ('special', 102),\n",
       " ('price', 102),\n",
       " ('same', 102),\n",
       " ('ship', 102),\n",
       " ('plan', 101),\n",
       " ('u', 101),\n",
       " ('thousand', 100),\n",
       " ('sure', 100),\n",
       " ('again', 100),\n",
       " ('great', 99),\n",
       " ('capitalfm', 99),\n",
       " ('type', 97),\n",
       " ('server', 94),\n",
       " ('four', 94),\n",
       " ('simply', 93),\n",
       " ('step', 93),\n",
       " ('off', 92),\n",
       " ('where', 92),\n",
       " ('guarantee', 90),\n",
       " ('keep', 90),\n",
       " ('full', 90),\n",
       " ('next', 90),\n",
       " ('member', 89),\n",
       " ('purchase', 88),\n",
       " ('etc', 88),\n",
       " ('search', 88),\n",
       " ('video', 88),\n",
       " ('box', 87),\n",
       " ('x', 87),\n",
       " ('package', 87),\n",
       " ('system', 87),\n",
       " ('question', 86),\n",
       " ('ve', 86),\n",
       " ('instruction', 85),\n",
       " ('never', 85),\n",
       " ('total', 85),\n",
       " ('thank', 85),\n",
       " ('sex', 83),\n",
       " ('friend', 83),\n",
       " ('return', 83),\n",
       " ('adult', 83),\n",
       " ('tell', 82),\n",
       " ('participate', 82),\n",
       " ('multi', 82),\n",
       " ('tax', 82),\n",
       " ('part', 81),\n",
       " ('little', 81),\n",
       " ('simple', 81),\n",
       " ('ad', 81),\n",
       " ('life', 81),\n",
       " ('put', 80),\n",
       " ('amount', 80),\n",
       " ('rate', 80),\n",
       " ('under', 80),\n",
       " ('result', 79),\n",
       " ('different', 79),\n",
       " ('two', 79),\n",
       " ('bank', 78),\n",
       " ('request', 78),\n",
       " ('response', 77),\n",
       " ('method', 77),\n",
       " ('date', 77),\n",
       " ('let', 77),\n",
       " ('change', 76),\n",
       " ('bonus', 76),\n",
       " ('important', 76),\n",
       " ('really', 76),\n",
       " ('why', 76),\n",
       " ('least', 76),\n",
       " ('bill', 76),\n",
       " ('course', 75),\n",
       " ('personal', 75),\n",
       " ('base', 75),\n",
       " ('join', 75),\n",
       " ('plus', 75),\n",
       " ('online', 75),\n",
       " ('manual', 75)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_spam = spam_train_counts.most_common(200)\n",
    "top_200_legit = legit_train_counts.most_common(200)\n",
    "top_400 = list(set(top_200_legit + top_200_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 200 from each class\n",
    "merged_top400 = pd.DataFrame()\n",
    "for w in top_400:\n",
    "    merged_top400 = pd.concat([probs[probs[\"all_words\"]==w], merged_top400],ignore_index=True)\n",
    "\n",
    "#Top 200 Spam word probabilities and classes\n",
    "spam_top200_probabilities = pd.DataFrame()\n",
    "for a in top_200_spam:\n",
    "    spam_top200_probabilities = pd.concat([probs[probs[\"all_words\"]==a], spam_top200_probabilities],ignore_index=True)\n",
    "    \n",
    "\n",
    "#Top 200 Legitmate word probabilities and classes\n",
    "legitimate_top200_probabilities = pd.DataFrame()\n",
    "for b in top_200_legit:\n",
    "    legitimate_top200_probabilities = pd.concat([probs[probs[\"all_words\"]==b], legitimate_top200_probabilities],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(email):\n",
    "    spam_prob = 1\n",
    "    legit_prob = 1\n",
    "    \n",
    "    words = []\n",
    "    word = email.split()\n",
    "    for i in word:\n",
    "        if i.isalpha():\n",
    "            words.append(i)\n",
    "        \n",
    "    for w in words:\n",
    "        tmp = merged_top400[merged_top400['all_words'] == w]\n",
    "        if tmp.shape[0] > 1:\n",
    "            spam_prob = spam_prob * tmp['spam_prob'].values[0]\n",
    "            legit_prob = legit_prob * tmp['legit_prob'].values[0]\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if spam_prob > legit_prob:\n",
    "        return False\n",
    "    else:\n",
    "        return True        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    spam_wrong_count = 0\n",
    "    spam_correct_count = 0\n",
    "    \n",
    "    for spam in test_spam_mails:\n",
    "        sol = predict(spam)\n",
    "        if sol == True:\n",
    "            spam_correct_count += 1\n",
    "        else:\n",
    "            spam_wrong_count += 1  \n",
    "            \n",
    "    legit_wrong_count = 0\n",
    "    legit_correct_count = 0\n",
    "    \n",
    "    for legit in test_legitimate:\n",
    "        sol = predict(legit)\n",
    "        if sol == True:\n",
    "            legit_correct_count += 1\n",
    "        else:\n",
    "            legit_wrong_count += 1\n",
    "            \n",
    "    pred = pd.DataFrame()\n",
    "    pred['classification'] = ['legit', 'spam']\n",
    "    pred['wrong'] = [legit_wrong_count, spam_wrong_count]\n",
    "    pred['correct'] = [legit_correct_count, spam_correct_count]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>wrong</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification  wrong  correct\n",
       "0          legit      0      240\n",
       "1           spam      0      240"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
